version: "3.7"

services:
  caddy:
    container_name: caddy
    image: docker.io/library/caddy:2-alpine
    restart: unless-stopped
    networks:
      - searxng_network
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy-data:/data:rw
      - caddy-config:/config:rw
    environment:
      - SEARXNG_HOSTNAME=http://searxng:8080
      - SEARXNG_TLS=internal
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"

  redis:
    container_name: redis
    image: docker.io/valkey/valkey:8-alpine
    command: valkey-server --save 30 1 --loglevel warning
    restart: unless-stopped
    networks:
      - searxng_network
    volumes:
      - valkey-data2:/data
    cap_drop:
      - ALL
    cap_add:
      - SETGID
      - SETUID
      - DAC_OVERRIDE
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"

  searxng:
    container_name: searxng
    build:  # ✅ Now using the custom Dockerfile to install curl and wget
      context: .
      dockerfile: Dockerfile
    restart: unless-stopped
    networks:
      - searxng_network
    ports:
      - "8888:8080"
    volumes:
      - ./searxng:/etc/searxng:rw
    environment:
      - SEARXNG_BIND_ADDRESS=0.0.0.0:8080
      - SEARXNG_BASE_URL=http://searxng:8080/
      - UWSGI_WORKERS=4
      - UWSGI_THREADS=4
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080/"]
      interval: 20s
      retries: 5
      start_period: 40s

  postgres:
    container_name: postgres
    image: postgres:16
    environment:
      - POSTGRES_USER=openwebui_user
      - POSTGRES_PASSWORD=securepassword
      - POSTGRES_DB=openwebui_db
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: unless-stopped
    networks:
      - searxng_network
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"

  openwebui:
    container_name: openwebui
    image: ghcr.io/open-webui/open-webui:latest
    restart: unless-stopped
    networks:
      - searxng_network
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgresql://openwebui_user:securepassword@postgres:5432/openwebui_db
      - WEBUI_SECRET_KEY=replace_with_a_random_generated_key
      - USE_OLLAMA_DOCKER=true  # ✅ Enable Ollama inside Docker
      - OLLAMA_HOST=http://ollama:11434  # ✅ Corrected to use Ollama container
      - HF_HOME=/app/backend/data/cache/embedding/models
      - SEARXNG_QUERY_URL=http://searxng:8080/search?q=
      - SEARXNG_BASE_URL=http://searxng:8080/
    depends_on:
      postgres:
        condition: service_healthy
      searxng:
        condition: service_healthy  # ✅ Now waits for SearXNG to be fully healthy
      ollama:
        condition: service_healthy

  ollama:
    container_name: ollama
    image: ollama/ollama:latest
    restart: unless-stopped
    networks:
      - searxng_network
    ports:
      - "11434:11434"
    environment:
      - HF_HOME=/app/backend/data/cache/embedding/models

networks:
  searxng_network:
    driver: bridge

volumes:
  caddy-data:
  caddy-config:
  valkey-data2:
  postgres-data:
